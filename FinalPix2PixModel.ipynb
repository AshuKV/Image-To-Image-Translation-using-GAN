{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalPix2PixModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-39XHh6J1iEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "8c30490b-d72c-4ca7-d9a9-482821c9c72c"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "%cd pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)   \u001b[K\rremote: Counting objects:  50% (2/4)   \u001b[K\rremote: Counting objects:  75% (3/4)   \u001b[K\rremote: Counting objects: 100% (4/4)   \u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 2081 (delta 0), reused 0 (delta 0), pack-reused 2077\u001b[K\n",
            "Receiving objects: 100% (2081/2081), 7.97 MiB | 1.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1351/1351), done.\n",
            "/content/pytorch-CycleGAN-and-pix2pix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poPzdnY41521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "2687fbff-59c3-4c4b-ea52-37aa04737cd4"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.3.0)\n",
            "Collecting dominate>=2.3.1 (from -r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/54/50ec03a4b4114e2c02d049cc26fe6ad8f0653ba5d0cd55d7c9bf9a260434/dominate-2.3.5-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.3 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 27.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 31.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 36.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 38.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 41.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 41.6MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 41.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 44.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 44.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 44.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 122kB 44.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 44.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 44.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 44.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 44.7MB/s eta 0:00:01\r\u001b[K     |████                            | 174kB 44.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 184kB 44.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 44.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 235kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 245kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 286kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 307kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 317kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 348kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 358kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 368kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 378kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 399kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 409kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 419kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 430kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 440kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 460kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 471kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 481kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 491kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 501kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 512kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 522kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 532kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 542kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 563kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 573kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 583kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 604kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 614kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 624kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 634kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 645kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 655kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 665kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 675kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 686kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 696kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 706kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 716kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 727kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 737kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 747kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 757kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 768kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 778kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 788kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 798kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 808kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 819kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 829kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 839kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 849kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 860kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 870kB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 880kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 901kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 911kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 921kB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 931kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 942kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 952kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 962kB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 972kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 983kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 993kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.0MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 44.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.21.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (17.0.0)\n",
            "Collecting torchfile (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.2.1->-r requirements.txt (line 2)) (0.46)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/87/ce/a5023722374ca73b57fc8d4284ba6f973c01219b3c385a07e0\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.3.5 torchfile-0.1.0 visdom-0.1.8.8 websocket-client-0.56.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP1-BoB_2Lbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "25c4d511-6baf-4658-ed62-998373d4aa23"
      },
      "source": [
        "!bash ./datasets/download_cyclegan_dataset.sh maps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specified [maps]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2019-07-22 04:23:49--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/maps.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1476754427 (1.4G) [application/zip]\n",
            "Saving to: ‘./datasets/maps.zip’\n",
            "\n",
            "./datasets/maps.zip  21%[===>                ] 296.90M  21.4MB/s    eta 57s    ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og9FwlNF2XgX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "49267a93-f645-4d83-89d9-ee1fe61ad312"
      },
      "source": [
        "!python -m visdom.server"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking for scripts.\n",
            "It's Alive!\n",
            "INFO:root:Application Started\n",
            "You can navigate to http://a6b5e293bc4a:8097\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1308, in <module>\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1304, in download_scripts_and_run\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1299, in main\n",
            "    print_func=print_func, user_credential=user_credential)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/server.py\", line 1231, in start_server\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 863, in start\n",
            "    event_pairs = self._impl.poll(poll_timeout)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6bb12883JJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d8f372b5-aa8b-4c88-e058-4f9f54a8c3aa"
      },
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh night2day"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specified [night2day]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2019-07-22 10:12:01--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/night2day.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2063695642 (1.9G) [application/x-gzip]\n",
            "Saving to: ‘./datasets/night2day.tar.gz’\n",
            "\n",
            "      ./datasets/ni   0%[                    ]   8.66M  1.61MB/s    eta 58m 45s^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KGA_GSm3gsz"
      },
      "source": [
        "#!./scripts/train_pix2pix.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsVaEd1j9JJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "6595cbcc-e366-4318-f8b7-1702a599d1dc"
      },
      "source": [
        "!python train.py --dataroot ./datasets/night2day --name facades_pix2pix --model pix2pix --direction BtoA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 25, in <module>\n",
            "    from util.visualizer import Visualizer\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/util/visualizer.py\", line 8, in <module>\n",
            "    from scipy.misc import imresize\n",
            "ImportError: cannot import name 'imresize'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9NcyOkl-4ia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "3b3f7320-651c-4d7b-8d18-4c14fe9f58ef"
      },
      "source": [
        "!pip install scipy==1.1.0 --user"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS96w_-fOfDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "66a518b8-bed1-4520-af6b-b2e0e720b196"
      },
      "source": [
        "!bash ./scripts/download_pix2pix_model.sh day2night"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
            "Specified [day2night]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2019-07-23 06:32:07--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/day2night.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217710797 (208M)\n",
            "Saving to: ‘./checkpoints/day2night_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/day2n 100%[===================>] 207.62M  17.8MB/s    in 13s     \n",
            "\n",
            "2019-07-23 06:32:21 (15.9 MB/s) - ‘./checkpoints/day2night_pretrained/latest_net_G.pth’ saved [217710797/217710797]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxvdhXjKiB_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "46c1478c-3c20-4092-a356-bc71bf5e5655"
      },
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh night2day"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specified [night2day]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2019-07-23 06:34:22--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/night2day.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2063695642 (1.9G) [application/x-gzip]\n",
            "Saving to: ‘./datasets/night2day.tar.gz’\n",
            "\n",
            "ar.gz                 0%[                    ]   2.82M   356KB/s    eta 2h 24m ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v3pujaXPD9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "bb893096-d204-4c86-dd5b-28892903ad59"
      },
      "source": [
        "//!python test.py --dataroot ./datasets/MyData/ --direction BtoA --model pix2pix --name day2night_pretrained"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/MyData/            \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: day2night_pretrained          \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 45, in <module>\n",
            "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
            "    data_loader = CustomDatasetDataLoader(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
            "    self.dataset = dataset_class(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/aligned_dataset.py\", line 22, in __init__\n",
            "    self.AB_paths = sorted(make_dataset(self.dir_AB, opt.max_dataset_size))  # get image paths\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/image_folder.py\", line 25, in make_dataset\n",
            "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
            "AssertionError: ./datasets/MyData/test is not a valid directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ75YMz3j65H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "e03c5e18-e0d8-487c-a924-fbe5fa04d364"
      },
      "source": [
        "//!python datasets/combine_A_and_B.py --fold_A /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A --fold_B /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B --fold_AB /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[fold_A] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A\n",
            "[fold_B] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B\n",
            "[fold_AB] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData\n",
            "[num_imgs] =  1000000\n",
            "[use_AB] =  False\n",
            "Traceback (most recent call last):\n",
            "  File \"datasets/combine_A_and_B.py\", line 17, in <module>\n",
            "    splits = os.listdir(args.fold_A)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcUAdNcEkkzI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7246240a-50e1-4364-a6d5-48189f99cf6e"
      },
      "source": [
        "//!python train.py --dataroot ./datasets/MyData --model pix2pix --direction BtoA --epoch_count 1 --display_freq 1 --print_freq 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/MyData             \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "              display_env: main                          \n",
            "             display_freq: 1                             \t[default: 400]\n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "               n_layers_D: 3                             \n",
            "                     name: experiment_name               \n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 1                             \t[default: 100]\n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 29, in <module>\n",
            "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
            "    data_loader = CustomDatasetDataLoader(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
            "    self.dataset = dataset_class(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/aligned_dataset.py\", line 22, in __init__\n",
            "    self.AB_paths = sorted(make_dataset(self.dir_AB, opt.max_dataset_size))  # get image paths\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/image_folder.py\", line 25, in make_dataset\n",
            "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
            "AssertionError: ./datasets/MyData/train is not a valid directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAhLHMG8mlrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "abc883d1-cf53-49b4-9b6b-732200ed9d38"
      },
      "source": [
        "//!python test.py --dataroot ./datasets/MyData/ --direction AtoB --model pix2pix --name day2night_pretrained --netG unet_256 --dataset_mode aligned --norm batch "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/MyData/            \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: day2night_pretrained          \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 45, in <module>\n",
            "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 57, in create_dataset\n",
            "    data_loader = CustomDatasetDataLoader(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/__init__.py\", line 73, in __init__\n",
            "    self.dataset = dataset_class(opt)\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/aligned_dataset.py\", line 22, in __init__\n",
            "    self.AB_paths = sorted(make_dataset(self.dir_AB, opt.max_dataset_size))  # get image paths\n",
            "  File \"/content/pytorch-CycleGAN-and-pix2pix/data/image_folder.py\", line 25, in make_dataset\n",
            "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
            "AssertionError: ./datasets/MyData/test is not a valid directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vHAFCZYTkQN"
      },
      "source": [
        "!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgXLFLEgVA1G"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GdNPcq0VJTy"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs_M7XPJPlWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e55f7c1d-3679-47a6-a6d1-ffd2965fe73e"
      },
      "source": [
        "//!./scripts/download_pix2pix_model.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./scripts/download_pix2pix_model.sh: Permission denied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoTcQhTxVHzZ"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA8nUbS4WDCU"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A/val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao0XYD4gWGql"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt7bjsD9WIY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX6lnoDwWKaC"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sODrhrBzWNJU"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B/val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AVxMpU6WPrg"
      },
      "source": [
        "//!mkdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2MvZ6FWWRqC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJr6ElD_dbe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o51jzi9eRg3Z"
      },
      "source": [
        "//!cat /content/drive/My Drive/FinalDay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8_0MFaR0so"
      },
      "source": [
        "!mv /content/drive/My Drive/FinalDay/Atest /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FsZwsD_0EG7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4O_n_VO0EeI"
      },
      "source": [
        "//!wget /content/drive/My Drive/FinalDay/Atest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phCdUB_CGsRS"
      },
      "source": [
        "!unzip -uq \"/content/B.zip.zip\" -d \"/content/pytorch-CycleGAN-and-pix2pix/datasets/MyData\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sZk8IIwgEyy"
      },
      "source": [
        "!mv /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/FinalDay /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqgXgE3AHCsr"
      },
      "source": [
        "!mv /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/FinalNight /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujLWge7-HiVE"
      },
      "source": [
        "//!rmdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g7VA1_GIuuC"
      },
      "source": [
        "//!rmdir /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7dUZrhbg_S3"
      },
      "source": [
        "!unzip -uq '/content/A.zip.zip' -d '/content/pytorch-CycleGAN-and-pix2pix/datasets/MyData'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBZNdgZZ3qnc"
      },
      "source": [
        "//!python '''/content/pytorch-CycleGAN-and-pix2pix/data/base_dataset.py''' --dataroot /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A/test  --preprocess resize_and_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_YpdgPKBksK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "8399e053-1ced-4f3d-b3c2-b26f473b1da9"
      },
      "source": [
        "!python datasets/combine_A_and_B.py --fold_A /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A --fold_B /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B --fold_AB /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[fold_A] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/A\n",
            "[fold_B] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData/B\n",
            "[fold_AB] =  /content/pytorch-CycleGAN-and-pix2pix/datasets/MyData\n",
            "[num_imgs] =  1000000\n",
            "[use_AB] =  False\n",
            "split = train, use 16/16 images\n",
            "split = train, number of images = 16\n",
            "split = test, use 16/16 images\n",
            "split = test, number of images = 16\n",
            "split = val, use 16/16 images\n",
            "split = val, number of images = 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbrMobvpBD2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a871b5e-c29c-411b-cb57-0e8b5726feca"
      },
      "source": [
        "!python train.py --dataroot ./datasets/MyData --name day2night_MyData --model pix2pix --direction BtoA --niter 400 --niter_decay 400"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/MyData             \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "               n_layers_D: 3                             \n",
            "                     name: day2night_MyData              \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "                    niter: 400                           \t[default: 100]\n",
            "              niter_decay: 400                           \t[default: 100]\n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "The number of training images = 16\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "WARNING:root:Setting up a new session...\n",
            "create web directory ./checkpoints/day2night_MyData/web...\n",
            "End of epoch 1 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 4 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 5, iters 80\n",
            "End of epoch 5 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 4, time: 0.084, data: 0.352) G_GAN: 2.715 G_L1: 36.981 D_real: 0.137 D_fake: 0.563 \n",
            "End of epoch 7 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 10, iters 160\n",
            "End of epoch 10 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 12 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 13, iters: 8, time: 0.083, data: 0.000) G_GAN: 1.746 G_L1: 25.341 D_real: 0.239 D_fake: 0.321 \n",
            "End of epoch 13 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 14 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 15, iters 240\n",
            "End of epoch 15 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 17 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 19, iters: 12, time: 0.084, data: 0.002) G_GAN: 1.624 G_L1: 28.093 D_real: 0.105 D_fake: 0.123 \n",
            "End of epoch 19 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 20, iters 320\n",
            "End of epoch 20 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 23 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 24 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 25, iters: 16, time: 0.335, data: 0.001) G_GAN: 3.857 G_L1: 39.109 D_real: 0.124 D_fake: 0.045 \n",
            "saving the model at the end of epoch 25, iters 400\n",
            "End of epoch 25 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 27 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 30, iters 480\n",
            "End of epoch 30 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 32, iters: 4, time: 0.080, data: 0.288) G_GAN: 2.247 G_L1: 25.669 D_real: 0.150 D_fake: 0.413 \n",
            "End of epoch 32 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 34 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 35, iters 560\n",
            "End of epoch 35 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 37 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 38, iters: 8, time: 0.085, data: 0.002) G_GAN: 2.280 G_L1: 23.083 D_real: 0.194 D_fake: 0.442 \n",
            "End of epoch 38 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 40, iters 640\n",
            "End of epoch 40 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 12, time: 0.084, data: 0.002) G_GAN: 1.412 G_L1: 19.530 D_real: 0.544 D_fake: 0.207 \n",
            "End of epoch 44 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 45, iters 720\n",
            "End of epoch 45 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 47 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 16, time: 0.383, data: 0.001) G_GAN: 3.583 G_L1: 19.876 D_real: 0.052 D_fake: 0.267 \n",
            "saving the model at the end of epoch 50, iters 800\n",
            "End of epoch 50 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 54 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 55, iters 880\n",
            "End of epoch 55 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 56 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 4, time: 0.082, data: 0.335) G_GAN: 2.194 G_L1: 32.777 D_real: 0.688 D_fake: 0.076 \n",
            "End of epoch 57 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 60, iters 960\n",
            "End of epoch 60 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 63, iters: 8, time: 0.085, data: 0.005) G_GAN: 0.382 G_L1: 15.355 D_real: 0.829 D_fake: 0.257 \n",
            "End of epoch 63 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 64 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 65, iters 1040\n",
            "End of epoch 65 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 67 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 69, iters: 12, time: 0.084, data: 0.003) G_GAN: 1.682 G_L1: 21.741 D_real: 1.344 D_fake: 0.115 \n",
            "End of epoch 69 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 70, iters 1120\n",
            "End of epoch 70 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 74 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 75, iters: 16, time: 0.439, data: 0.002) G_GAN: 2.279 G_L1: 20.239 D_real: 0.078 D_fake: 0.849 \n",
            "saving the model at the end of epoch 75, iters 1200\n",
            "End of epoch 75 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 77 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 78 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 80, iters 1280\n",
            "End of epoch 80 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 82, iters: 4, time: 0.079, data: 0.338) G_GAN: 1.245 G_L1: 15.842 D_real: 0.663 D_fake: 0.141 \n",
            "End of epoch 82 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 84 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 85, iters 1360\n",
            "End of epoch 85 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 87 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 88, iters: 8, time: 0.086, data: 0.001) G_GAN: 1.354 G_L1: 18.549 D_real: 0.452 D_fake: 0.222 \n",
            "End of epoch 88 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 89 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 90, iters 1440\n",
            "End of epoch 90 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 12, time: 0.086, data: 0.002) G_GAN: 1.228 G_L1: 25.116 D_real: 0.509 D_fake: 0.614 \n",
            "End of epoch 94 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 95, iters 1520\n",
            "End of epoch 95 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 97 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 100, iters: 16, time: 0.539, data: 0.001) G_GAN: 1.324 G_L1: 24.927 D_real: 0.859 D_fake: 0.136 \n",
            "saving the model at the end of epoch 100, iters 1600\n",
            "End of epoch 100 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 101 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 102 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 103 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 104 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 105, iters 1680\n",
            "End of epoch 105 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 106 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 107, iters: 4, time: 0.085, data: 0.289) G_GAN: 2.094 G_L1: 23.726 D_real: 0.196 D_fake: 1.074 \n",
            "End of epoch 107 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 108 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 109 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 110, iters 1760\n",
            "End of epoch 110 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 111 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 112 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 113, iters: 8, time: 0.086, data: 0.001) G_GAN: 1.992 G_L1: 23.862 D_real: 0.146 D_fake: 0.464 \n",
            "End of epoch 113 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 114 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 115, iters 1840\n",
            "End of epoch 115 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 116 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 117 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 118 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 119, iters: 12, time: 0.087, data: 0.002) G_GAN: 1.509 G_L1: 15.557 D_real: 0.364 D_fake: 0.239 \n",
            "End of epoch 119 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 120, iters 1920\n",
            "End of epoch 120 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 121 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 122 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 123 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 124 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 125, iters: 16, time: 0.642, data: 0.002) G_GAN: 2.178 G_L1: 16.394 D_real: 0.285 D_fake: 0.194 \n",
            "saving the model at the end of epoch 125, iters 2000\n",
            "End of epoch 125 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 126 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 127 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 128 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 129 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 130, iters 2080\n",
            "End of epoch 130 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 131 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 132, iters: 4, time: 0.080, data: 0.335) G_GAN: 1.960 G_L1: 15.160 D_real: 0.186 D_fake: 0.396 \n",
            "End of epoch 132 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 133 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 134 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 135, iters 2160\n",
            "End of epoch 135 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 136 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 137 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 138, iters: 8, time: 0.087, data: 0.003) G_GAN: 1.856 G_L1: 16.617 D_real: 0.348 D_fake: 0.412 \n",
            "End of epoch 138 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 139 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 140, iters 2240\n",
            "End of epoch 140 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 141 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 142 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 143 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 144, iters: 12, time: 0.085, data: 0.000) G_GAN: 1.582 G_L1: 17.342 D_real: 0.441 D_fake: 0.240 \n",
            "End of epoch 144 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 145, iters 2320\n",
            "End of epoch 145 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 146 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 147 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 148 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 149 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 150, iters: 16, time: 0.677, data: 0.001) G_GAN: 2.147 G_L1: 14.972 D_real: 0.394 D_fake: 0.227 \n",
            "saving the model at the end of epoch 150, iters 2400\n",
            "End of epoch 150 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 151 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 152 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 153 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 154 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 155, iters 2480\n",
            "End of epoch 155 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 156 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 157, iters: 4, time: 0.081, data: 0.337) G_GAN: 2.097 G_L1: 16.740 D_real: 0.355 D_fake: 0.381 \n",
            "End of epoch 157 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 158 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 159 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 160, iters 2560\n",
            "End of epoch 160 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 161 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 162 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 163, iters: 8, time: 0.087, data: 0.000) G_GAN: 1.580 G_L1: 18.446 D_real: 0.431 D_fake: 0.329 \n",
            "End of epoch 163 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 164 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 165, iters 2640\n",
            "End of epoch 165 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 166 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 167 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 168 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 169, iters: 12, time: 0.087, data: 0.002) G_GAN: 2.117 G_L1: 18.930 D_real: 0.245 D_fake: 0.363 \n",
            "End of epoch 169 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 170, iters 2720\n",
            "End of epoch 170 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 171 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 172 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 173 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 174 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 175, iters: 16, time: 0.750, data: 0.002) G_GAN: 1.557 G_L1: 16.381 D_real: 0.555 D_fake: 0.198 \n",
            "saving the model at the end of epoch 175, iters 2800\n",
            "End of epoch 175 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 176 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 177 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 178 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 179 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 180, iters 2880\n",
            "End of epoch 180 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 181 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 182, iters: 4, time: 0.079, data: 0.375) G_GAN: 2.109 G_L1: 23.843 D_real: 0.432 D_fake: 0.191 \n",
            "End of epoch 182 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 183 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 184 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 185, iters 2960\n",
            "End of epoch 185 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 186 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 187 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 188, iters: 8, time: 0.088, data: 0.000) G_GAN: 2.177 G_L1: 16.594 D_real: 0.325 D_fake: 0.369 \n",
            "End of epoch 188 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 189 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 190, iters 3040\n",
            "End of epoch 190 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 191 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 192 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 193 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 194, iters: 12, time: 0.086, data: 0.003) G_GAN: 2.090 G_L1: 14.534 D_real: 0.269 D_fake: 0.466 \n",
            "End of epoch 194 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 195, iters 3120\n",
            "End of epoch 195 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 196 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 197 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 198 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 199 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 200, iters: 16, time: 0.808, data: 0.001) G_GAN: 2.560 G_L1: 17.145 D_real: 0.178 D_fake: 0.896 \n",
            "saving the model at the end of epoch 200, iters 3200\n",
            "End of epoch 200 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 201 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 202 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 203 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 204 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 205, iters 3280\n",
            "End of epoch 205 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 206 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 207, iters: 4, time: 0.081, data: 0.335) G_GAN: 1.580 G_L1: 16.979 D_real: 0.489 D_fake: 0.205 \n",
            "End of epoch 207 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 208 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 209 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 210, iters 3360\n",
            "End of epoch 210 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 211 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 212 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 213, iters: 8, time: 0.086, data: 0.000) G_GAN: 1.939 G_L1: 15.831 D_real: 0.298 D_fake: 0.333 \n",
            "End of epoch 213 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 214 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 215, iters 3440\n",
            "End of epoch 215 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 216 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 217 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 218 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 219, iters: 12, time: 0.087, data: 0.002) G_GAN: 1.761 G_L1: 17.084 D_real: 0.200 D_fake: 0.556 \n",
            "End of epoch 219 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 220, iters 3520\n",
            "End of epoch 220 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 221 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 222 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 223 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 224 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 225, iters: 16, time: 0.955, data: 0.002) G_GAN: 2.042 G_L1: 14.088 D_real: 0.421 D_fake: 0.108 \n",
            "saving the model at the end of epoch 225, iters 3600\n",
            "End of epoch 225 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 226 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 227 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 228 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 229 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 230, iters 3680\n",
            "End of epoch 230 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 231 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 232, iters: 4, time: 0.090, data: 0.373) G_GAN: 1.227 G_L1: 14.957 D_real: 1.007 D_fake: 0.149 \n",
            "End of epoch 232 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 233 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 234 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 235, iters 3760\n",
            "End of epoch 235 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 236 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 237 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 238, iters: 8, time: 0.089, data: 0.002) G_GAN: 2.447 G_L1: 14.126 D_real: 0.130 D_fake: 0.884 \n",
            "End of epoch 238 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 239 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 240, iters 3840\n",
            "End of epoch 240 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 241 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 242 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 243 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 244, iters: 12, time: 0.087, data: 0.001) G_GAN: 1.869 G_L1: 16.988 D_real: 0.143 D_fake: 0.536 \n",
            "End of epoch 244 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 245, iters 3920\n",
            "End of epoch 245 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 246 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 247 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 248 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 249 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 250, iters: 16, time: 0.954, data: 0.001) G_GAN: 1.990 G_L1: 15.372 D_real: 0.283 D_fake: 0.187 \n",
            "saving the model at the end of epoch 250, iters 4000\n",
            "End of epoch 250 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 251 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 252 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 253 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 254 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 255, iters 4080\n",
            "End of epoch 255 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 256 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 257, iters: 4, time: 0.090, data: 0.366) G_GAN: 2.848 G_L1: 15.712 D_real: 0.352 D_fake: 0.091 \n",
            "End of epoch 257 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 258 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 259 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 260, iters 4160\n",
            "End of epoch 260 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 261 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 262 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 263, iters: 8, time: 0.089, data: 0.000) G_GAN: 1.688 G_L1: 14.857 D_real: 0.335 D_fake: 0.380 \n",
            "End of epoch 263 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 264 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 265, iters 4240\n",
            "End of epoch 265 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 266 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 267 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 268 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 269, iters: 12, time: 0.087, data: 0.002) G_GAN: 1.855 G_L1: 16.073 D_real: 0.168 D_fake: 0.443 \n",
            "End of epoch 269 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 270, iters 4320\n",
            "End of epoch 270 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 271 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 272 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 273 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 274 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 275, iters: 16, time: 1.025, data: 0.001) G_GAN: 1.973 G_L1: 14.215 D_real: 0.356 D_fake: 0.122 \n",
            "saving the model at the end of epoch 275, iters 4400\n",
            "End of epoch 275 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 276 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 277 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 278 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 279 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 280, iters 4480\n",
            "End of epoch 280 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 281 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 282, iters: 4, time: 0.084, data: 0.391) G_GAN: 2.004 G_L1: 15.473 D_real: 0.330 D_fake: 0.400 \n",
            "End of epoch 282 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 283 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 284 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 285, iters 4560\n",
            "End of epoch 285 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 286 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 287 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 288, iters: 8, time: 0.087, data: 0.005) G_GAN: 1.440 G_L1: 15.653 D_real: 0.995 D_fake: 0.057 \n",
            "End of epoch 288 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 289 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 290, iters 4640\n",
            "End of epoch 290 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 291 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 292 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 293 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 294, iters: 12, time: 0.087, data: 0.001) G_GAN: 2.161 G_L1: 15.294 D_real: 0.435 D_fake: 0.186 \n",
            "End of epoch 294 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 295, iters 4720\n",
            "End of epoch 295 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 296 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 297 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 298 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 299 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 300, iters: 16, time: 1.175, data: 0.001) G_GAN: 2.963 G_L1: 14.813 D_real: 0.111 D_fake: 0.332 \n",
            "saving the model at the end of epoch 300, iters 4800\n",
            "End of epoch 300 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 301 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 302 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 303 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 304 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 305, iters 4880\n",
            "End of epoch 305 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 306 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 307, iters: 4, time: 0.084, data: 0.360) G_GAN: 3.160 G_L1: 17.939 D_real: 0.151 D_fake: 0.251 \n",
            "End of epoch 307 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 308 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 309 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 310, iters 4960\n",
            "End of epoch 310 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 311 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 312 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 313, iters: 8, time: 0.086, data: 0.003) G_GAN: 2.321 G_L1: 17.658 D_real: 0.297 D_fake: 0.216 \n",
            "saving the latest model (epoch 313, total_iters 5000)\n",
            "End of epoch 313 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 314 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 315, iters 5040\n",
            "End of epoch 315 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 316 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 317 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 318 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 319, iters: 12, time: 0.084, data: 0.003) G_GAN: 3.657 G_L1: 13.712 D_real: 0.296 D_fake: 0.537 \n",
            "End of epoch 319 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 320, iters 5120\n",
            "End of epoch 320 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 321 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 322 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 323 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 324 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 325, iters: 16, time: 1.149, data: 0.002) G_GAN: 2.020 G_L1: 16.780 D_real: 0.983 D_fake: 0.054 \n",
            "saving the model at the end of epoch 325, iters 5200\n",
            "End of epoch 325 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 326 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 327 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 328 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 329 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 330, iters 5280\n",
            "End of epoch 330 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 331 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 332, iters: 4, time: 0.084, data: 0.333) G_GAN: 1.705 G_L1: 14.251 D_real: 0.633 D_fake: 0.085 \n",
            "End of epoch 332 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 333 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 334 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 335, iters 5360\n",
            "End of epoch 335 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 336 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 337 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 338, iters: 8, time: 0.087, data: 0.004) G_GAN: 3.170 G_L1: 13.108 D_real: 0.076 D_fake: 0.493 \n",
            "End of epoch 338 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 339 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 340, iters 5440\n",
            "End of epoch 340 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 341 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 342 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 343 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 344, iters: 12, time: 0.086, data: 0.003) G_GAN: 1.961 G_L1: 14.676 D_real: 0.644 D_fake: 0.187 \n",
            "End of epoch 344 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 345, iters 5520\n",
            "End of epoch 345 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 346 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 347 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 348 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 349 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 350, iters: 16, time: 1.292, data: 0.001) G_GAN: 2.814 G_L1: 14.251 D_real: 0.213 D_fake: 0.112 \n",
            "saving the model at the end of epoch 350, iters 5600\n",
            "End of epoch 350 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 351 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 352 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 353 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 354 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 355, iters 5680\n",
            "End of epoch 355 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 356 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 357, iters: 4, time: 0.085, data: 0.307) G_GAN: 2.246 G_L1: 17.237 D_real: 0.462 D_fake: 0.105 \n",
            "End of epoch 357 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 358 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 359 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 360, iters 5760\n",
            "End of epoch 360 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 361 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 362 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 363, iters: 8, time: 0.087, data: 0.004) G_GAN: 1.609 G_L1: 16.479 D_real: 0.713 D_fake: 0.110 \n",
            "End of epoch 363 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 364 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 365, iters 5840\n",
            "End of epoch 365 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 366 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 367 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 368 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 369, iters: 12, time: 0.087, data: 0.001) G_GAN: 2.399 G_L1: 14.193 D_real: 0.107 D_fake: 0.188 \n",
            "End of epoch 369 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 370, iters 5920\n",
            "End of epoch 370 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 371 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 372 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 373 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 374 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 375, iters: 16, time: 1.300, data: 0.002) G_GAN: 3.510 G_L1: 13.874 D_real: 0.476 D_fake: 0.342 \n",
            "saving the model at the end of epoch 375, iters 6000\n",
            "End of epoch 375 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 376 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 377 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 378 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 379 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 380, iters 6080\n",
            "End of epoch 380 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 381 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 382, iters: 4, time: 0.085, data: 0.398) G_GAN: 2.079 G_L1: 15.430 D_real: 0.311 D_fake: 0.228 \n",
            "End of epoch 382 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 383 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 384 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 385, iters 6160\n",
            "End of epoch 385 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 386 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 387 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 388, iters: 8, time: 0.087, data: 0.004) G_GAN: 3.459 G_L1: 12.295 D_real: 0.044 D_fake: 0.695 \n",
            "End of epoch 388 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 389 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 390, iters 6240\n",
            "End of epoch 390 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 391 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 392 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 393 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 394, iters: 12, time: 0.086, data: 0.003) G_GAN: 2.323 G_L1: 13.791 D_real: 0.092 D_fake: 0.162 \n",
            "End of epoch 394 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 395, iters 6320\n",
            "End of epoch 395 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 396 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 397 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 398 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 399 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 400, iters: 16, time: 1.432, data: 0.001) G_GAN: 2.017 G_L1: 16.178 D_real: 0.215 D_fake: 0.193 \n",
            "saving the model at the end of epoch 400, iters 6400\n",
            "End of epoch 400 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001995\n",
            "End of epoch 401 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001990\n",
            "End of epoch 402 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001985\n",
            "End of epoch 403 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001980\n",
            "End of epoch 404 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001975\n",
            "saving the model at the end of epoch 405, iters 6480\n",
            "End of epoch 405 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001970\n",
            "End of epoch 406 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001965\n",
            "(epoch: 407, iters: 4, time: 0.083, data: 0.433) G_GAN: 3.027 G_L1: 15.021 D_real: 0.294 D_fake: 0.074 \n",
            "End of epoch 407 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 408 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001955\n",
            "End of epoch 409 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001950\n",
            "saving the model at the end of epoch 410, iters 6560\n",
            "End of epoch 410 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001945\n",
            "End of epoch 411 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001940\n",
            "End of epoch 412 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001935\n",
            "(epoch: 413, iters: 8, time: 0.088, data: 0.003) G_GAN: 2.187 G_L1: 14.623 D_real: 0.641 D_fake: 0.431 \n",
            "End of epoch 413 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001930\n",
            "End of epoch 414 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001925\n",
            "saving the model at the end of epoch 415, iters 6640\n",
            "End of epoch 415 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001920\n",
            "End of epoch 416 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001915\n",
            "End of epoch 417 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001910\n",
            "End of epoch 418 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001905\n",
            "(epoch: 419, iters: 12, time: 0.087, data: 0.002) G_GAN: 2.058 G_L1: 14.825 D_real: 0.546 D_fake: 0.189 \n",
            "End of epoch 419 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001900\n",
            "saving the model at the end of epoch 420, iters 6720\n",
            "End of epoch 420 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001895\n",
            "End of epoch 421 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001890\n",
            "End of epoch 422 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001885\n",
            "End of epoch 423 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001880\n",
            "End of epoch 424 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001875\n",
            "(epoch: 425, iters: 16, time: 1.444, data: 0.001) G_GAN: 1.967 G_L1: 14.367 D_real: 0.126 D_fake: 0.470 \n",
            "saving the model at the end of epoch 425, iters 6800\n",
            "End of epoch 425 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001870\n",
            "End of epoch 426 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001865\n",
            "End of epoch 427 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001860\n",
            "End of epoch 428 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001855\n",
            "End of epoch 429 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001850\n",
            "saving the model at the end of epoch 430, iters 6880\n",
            "End of epoch 430 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001845\n",
            "End of epoch 431 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001840\n",
            "(epoch: 432, iters: 4, time: 0.084, data: 0.738) G_GAN: 2.094 G_L1: 16.093 D_real: 0.200 D_fake: 0.260 \n",
            "End of epoch 432 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001835\n",
            "End of epoch 433 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001830\n",
            "End of epoch 434 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001825\n",
            "saving the model at the end of epoch 435, iters 6960\n",
            "End of epoch 435 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001820\n",
            "End of epoch 436 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001815\n",
            "End of epoch 437 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001810\n",
            "(epoch: 438, iters: 8, time: 0.088, data: 0.002) G_GAN: 2.721 G_L1: 14.832 D_real: 0.076 D_fake: 0.596 \n",
            "End of epoch 438 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001805\n",
            "End of epoch 439 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001800\n",
            "saving the model at the end of epoch 440, iters 7040\n",
            "End of epoch 440 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001796\n",
            "End of epoch 441 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001791\n",
            "End of epoch 442 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001786\n",
            "End of epoch 443 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001781\n",
            "(epoch: 444, iters: 12, time: 0.088, data: 0.001) G_GAN: 2.905 G_L1: 14.704 D_real: 0.194 D_fake: 0.085 \n",
            "End of epoch 444 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001776\n",
            "saving the model at the end of epoch 445, iters 7120\n",
            "End of epoch 445 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001771\n",
            "End of epoch 446 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001766\n",
            "End of epoch 447 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001761\n",
            "End of epoch 448 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001756\n",
            "End of epoch 449 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001751\n",
            "(epoch: 450, iters: 16, time: 1.565, data: 0.001) G_GAN: 2.239 G_L1: 13.270 D_real: 0.161 D_fake: 0.322 \n",
            "saving the model at the end of epoch 450, iters 7200\n",
            "End of epoch 450 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001746\n",
            "End of epoch 451 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001741\n",
            "End of epoch 452 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001736\n",
            "End of epoch 453 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001731\n",
            "End of epoch 454 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001726\n",
            "saving the model at the end of epoch 455, iters 7280\n",
            "End of epoch 455 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001721\n",
            "End of epoch 456 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001716\n",
            "(epoch: 457, iters: 4, time: 0.084, data: 0.389) G_GAN: 2.617 G_L1: 14.494 D_real: 0.056 D_fake: 0.608 \n",
            "End of epoch 457 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001711\n",
            "End of epoch 458 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001706\n",
            "End of epoch 459 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001701\n",
            "saving the model at the end of epoch 460, iters 7360\n",
            "End of epoch 460 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001696\n",
            "End of epoch 461 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001691\n",
            "End of epoch 462 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001686\n",
            "(epoch: 463, iters: 8, time: 0.089, data: 0.003) G_GAN: 2.377 G_L1: 13.288 D_real: 0.170 D_fake: 0.394 \n",
            "End of epoch 463 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001681\n",
            "End of epoch 464 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001676\n",
            "saving the model at the end of epoch 465, iters 7440\n",
            "End of epoch 465 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001671\n",
            "End of epoch 466 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001666\n",
            "End of epoch 467 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001661\n",
            "End of epoch 468 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001656\n",
            "(epoch: 469, iters: 12, time: 0.087, data: 0.002) G_GAN: 2.683 G_L1: 15.258 D_real: 0.156 D_fake: 0.457 \n",
            "End of epoch 469 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001651\n",
            "saving the model at the end of epoch 470, iters 7520\n",
            "End of epoch 470 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001646\n",
            "End of epoch 471 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001641\n",
            "End of epoch 472 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001636\n",
            "End of epoch 473 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001631\n",
            "End of epoch 474 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001626\n",
            "(epoch: 475, iters: 16, time: 1.595, data: 0.001) G_GAN: 3.031 G_L1: 13.080 D_real: 0.123 D_fake: 0.117 \n",
            "saving the model at the end of epoch 475, iters 7600\n",
            "End of epoch 475 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001621\n",
            "End of epoch 476 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001616\n",
            "End of epoch 477 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001611\n",
            "End of epoch 478 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001606\n",
            "End of epoch 479 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001601\n",
            "saving the model at the end of epoch 480, iters 7680\n",
            "End of epoch 480 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001596\n",
            "End of epoch 481 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001591\n",
            "(epoch: 482, iters: 4, time: 0.084, data: 0.372) G_GAN: 2.984 G_L1: 14.186 D_real: 0.151 D_fake: 0.287 \n",
            "End of epoch 482 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001586\n",
            "End of epoch 483 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001581\n",
            "End of epoch 484 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001576\n",
            "saving the model at the end of epoch 485, iters 7760\n",
            "End of epoch 485 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001571\n",
            "End of epoch 486 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001566\n",
            "End of epoch 487 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001561\n",
            "(epoch: 488, iters: 8, time: 0.085, data: 0.000) G_GAN: 2.954 G_L1: 15.501 D_real: 0.242 D_fake: 0.115 \n",
            "End of epoch 488 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001556\n",
            "End of epoch 489 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001551\n",
            "saving the model at the end of epoch 490, iters 7840\n",
            "End of epoch 490 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001546\n",
            "End of epoch 491 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001541\n",
            "End of epoch 492 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001536\n",
            "End of epoch 493 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001531\n",
            "(epoch: 494, iters: 12, time: 0.087, data: 0.002) G_GAN: 2.615 G_L1: 14.590 D_real: 0.074 D_fake: 0.450 \n",
            "End of epoch 494 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001526\n",
            "saving the model at the end of epoch 495, iters 7920\n",
            "End of epoch 495 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001521\n",
            "End of epoch 496 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001516\n",
            "End of epoch 497 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001511\n",
            "End of epoch 498 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001506\n",
            "End of epoch 499 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001501\n",
            "(epoch: 500, iters: 16, time: 1.719, data: 0.001) G_GAN: 2.459 G_L1: 13.904 D_real: 0.158 D_fake: 0.328 \n",
            "saving the model at the end of epoch 500, iters 8000\n",
            "End of epoch 500 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001496\n",
            "End of epoch 501 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001491\n",
            "End of epoch 502 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001486\n",
            "End of epoch 503 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001481\n",
            "End of epoch 504 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001476\n",
            "saving the model at the end of epoch 505, iters 8080\n",
            "End of epoch 505 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001471\n",
            "End of epoch 506 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001466\n",
            "(epoch: 507, iters: 4, time: 0.082, data: 0.360) G_GAN: 1.973 G_L1: 14.675 D_real: 0.701 D_fake: 0.045 \n",
            "End of epoch 507 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001461\n",
            "End of epoch 508 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001456\n",
            "End of epoch 509 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001451\n",
            "saving the model at the end of epoch 510, iters 8160\n",
            "End of epoch 510 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001446\n",
            "End of epoch 511 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001441\n",
            "End of epoch 512 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001436\n",
            "(epoch: 513, iters: 8, time: 0.086, data: 0.004) G_GAN: 2.928 G_L1: 13.753 D_real: 0.226 D_fake: 0.051 \n",
            "End of epoch 513 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001431\n",
            "End of epoch 514 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001426\n",
            "saving the model at the end of epoch 515, iters 8240\n",
            "End of epoch 515 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001421\n",
            "End of epoch 516 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001416\n",
            "End of epoch 517 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001411\n",
            "End of epoch 518 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001406\n",
            "(epoch: 519, iters: 12, time: 0.087, data: 0.003) G_GAN: 1.998 G_L1: 13.486 D_real: 0.434 D_fake: 0.072 \n",
            "End of epoch 519 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001401\n",
            "saving the model at the end of epoch 520, iters 8320\n",
            "End of epoch 520 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001397\n",
            "End of epoch 521 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001392\n",
            "End of epoch 522 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001387\n",
            "End of epoch 523 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001382\n",
            "End of epoch 524 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001377\n",
            "(epoch: 525, iters: 16, time: 1.784, data: 0.001) G_GAN: 2.710 G_L1: 14.004 D_real: 0.093 D_fake: 0.359 \n",
            "saving the model at the end of epoch 525, iters 8400\n",
            "End of epoch 525 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001372\n",
            "End of epoch 526 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001367\n",
            "End of epoch 527 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001362\n",
            "End of epoch 528 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001357\n",
            "End of epoch 529 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001352\n",
            "saving the model at the end of epoch 530, iters 8480\n",
            "End of epoch 530 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001347\n",
            "End of epoch 531 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001342\n",
            "(epoch: 532, iters: 4, time: 0.085, data: 0.410) G_GAN: 2.516 G_L1: 14.014 D_real: 0.112 D_fake: 0.125 \n",
            "End of epoch 532 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001337\n",
            "End of epoch 533 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001332\n",
            "End of epoch 534 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001327\n",
            "saving the model at the end of epoch 535, iters 8560\n",
            "End of epoch 535 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001322\n",
            "End of epoch 536 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001317\n",
            "End of epoch 537 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001312\n",
            "(epoch: 538, iters: 8, time: 0.085, data: 0.004) G_GAN: 3.121 G_L1: 14.110 D_real: 0.175 D_fake: 0.106 \n",
            "End of epoch 538 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001307\n",
            "End of epoch 539 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001302\n",
            "saving the model at the end of epoch 540, iters 8640\n",
            "End of epoch 540 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001297\n",
            "End of epoch 541 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001292\n",
            "End of epoch 542 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001287\n",
            "End of epoch 543 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001282\n",
            "(epoch: 544, iters: 12, time: 0.086, data: 0.002) G_GAN: 2.880 G_L1: 14.880 D_real: 0.099 D_fake: 0.326 \n",
            "End of epoch 544 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001277\n",
            "saving the model at the end of epoch 545, iters 8720\n",
            "End of epoch 545 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001272\n",
            "End of epoch 546 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001267\n",
            "End of epoch 547 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001262\n",
            "End of epoch 548 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001257\n",
            "End of epoch 549 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001252\n",
            "(epoch: 550, iters: 16, time: 1.856, data: 0.002) G_GAN: 2.677 G_L1: 14.341 D_real: 0.196 D_fake: 0.083 \n",
            "saving the model at the end of epoch 550, iters 8800\n",
            "End of epoch 550 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001247\n",
            "End of epoch 551 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001242\n",
            "End of epoch 552 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001237\n",
            "End of epoch 553 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001232\n",
            "End of epoch 554 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001227\n",
            "saving the model at the end of epoch 555, iters 8880\n",
            "End of epoch 555 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001222\n",
            "End of epoch 556 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001217\n",
            "(epoch: 557, iters: 4, time: 0.087, data: 0.302) G_GAN: 2.777 G_L1: 14.537 D_real: 0.130 D_fake: 0.128 \n",
            "End of epoch 557 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001212\n",
            "End of epoch 558 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001207\n",
            "End of epoch 559 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001202\n",
            "saving the model at the end of epoch 560, iters 8960\n",
            "End of epoch 560 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001197\n",
            "End of epoch 561 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001192\n",
            "End of epoch 562 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001187\n",
            "(epoch: 563, iters: 8, time: 0.088, data: 0.005) G_GAN: 2.398 G_L1: 14.611 D_real: 0.394 D_fake: 0.110 \n",
            "End of epoch 563 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001182\n",
            "End of epoch 564 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001177\n",
            "saving the model at the end of epoch 565, iters 9040\n",
            "End of epoch 565 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001172\n",
            "End of epoch 566 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001167\n",
            "End of epoch 567 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001162\n",
            "End of epoch 568 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001157\n",
            "(epoch: 569, iters: 12, time: 0.080, data: 0.001) G_GAN: 2.891 G_L1: 13.633 D_real: 0.109 D_fake: 0.144 \n",
            "End of epoch 569 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001152\n",
            "saving the model at the end of epoch 570, iters 9120\n",
            "End of epoch 570 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001147\n",
            "End of epoch 571 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001142\n",
            "End of epoch 572 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001137\n",
            "End of epoch 573 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001132\n",
            "End of epoch 574 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001127\n",
            "(epoch: 575, iters: 16, time: 1.845, data: 0.001) G_GAN: 2.675 G_L1: 15.015 D_real: 0.166 D_fake: 0.163 \n",
            "saving the model at the end of epoch 575, iters 9200\n",
            "End of epoch 575 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001122\n",
            "End of epoch 576 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001117\n",
            "End of epoch 577 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001112\n",
            "End of epoch 578 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001107\n",
            "End of epoch 579 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001102\n",
            "saving the model at the end of epoch 580, iters 9280\n",
            "End of epoch 580 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001097\n",
            "End of epoch 581 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001092\n",
            "(epoch: 582, iters: 4, time: 0.088, data: 1.206) G_GAN: 2.714 G_L1: 15.095 D_real: 0.210 D_fake: 0.102 \n",
            "End of epoch 582 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001087\n",
            "End of epoch 583 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001082\n",
            "End of epoch 584 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001077\n",
            "saving the model at the end of epoch 585, iters 9360\n",
            "End of epoch 585 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001072\n",
            "End of epoch 586 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001067\n",
            "End of epoch 587 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001062\n",
            "(epoch: 588, iters: 8, time: 0.087, data: 0.004) G_GAN: 2.800 G_L1: 13.162 D_real: 0.056 D_fake: 0.320 \n",
            "End of epoch 588 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001057\n",
            "End of epoch 589 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001052\n",
            "saving the model at the end of epoch 590, iters 9440\n",
            "End of epoch 590 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001047\n",
            "End of epoch 591 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001042\n",
            "End of epoch 592 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001037\n",
            "End of epoch 593 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001032\n",
            "(epoch: 594, iters: 12, time: 0.087, data: 0.003) G_GAN: 3.124 G_L1: 14.098 D_real: 0.235 D_fake: 0.080 \n",
            "End of epoch 594 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001027\n",
            "saving the model at the end of epoch 595, iters 9520\n",
            "End of epoch 595 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001022\n",
            "End of epoch 596 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001017\n",
            "End of epoch 597 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001012\n",
            "End of epoch 598 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001007\n",
            "End of epoch 599 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0001002\n",
            "(epoch: 600, iters: 16, time: 1.995, data: 0.001) G_GAN: 3.072 G_L1: 13.561 D_real: 0.062 D_fake: 0.913 \n",
            "saving the model at the end of epoch 600, iters 9600\n",
            "End of epoch 600 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000998\n",
            "End of epoch 601 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000993\n",
            "End of epoch 602 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000988\n",
            "End of epoch 603 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000983\n",
            "End of epoch 604 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000978\n",
            "saving the model at the end of epoch 605, iters 9680\n",
            "End of epoch 605 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0000973\n",
            "End of epoch 606 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000968\n",
            "(epoch: 607, iters: 4, time: 0.082, data: 0.394) G_GAN: 2.809 G_L1: 15.213 D_real: 0.142 D_fake: 0.076 \n",
            "End of epoch 607 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000963\n",
            "End of epoch 608 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000958\n",
            "End of epoch 609 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000953\n",
            "saving the model at the end of epoch 610, iters 9760\n",
            "End of epoch 610 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000948\n",
            "End of epoch 611 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000943\n",
            "End of epoch 612 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000938\n",
            "(epoch: 613, iters: 8, time: 0.088, data: 0.004) G_GAN: 2.795 G_L1: 12.930 D_real: 0.097 D_fake: 0.122 \n",
            "End of epoch 613 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000933\n",
            "End of epoch 614 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000928\n",
            "saving the model at the end of epoch 615, iters 9840\n",
            "End of epoch 615 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000923\n",
            "End of epoch 616 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000918\n",
            "End of epoch 617 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000913\n",
            "End of epoch 618 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000908\n",
            "(epoch: 619, iters: 12, time: 0.087, data: 0.003) G_GAN: 3.098 G_L1: 14.173 D_real: 0.085 D_fake: 0.242 \n",
            "End of epoch 619 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000903\n",
            "saving the model at the end of epoch 620, iters 9920\n",
            "End of epoch 620 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000898\n",
            "End of epoch 621 / 800 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000893\n",
            "End of epoch 622 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000888\n",
            "End of epoch 623 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000883\n",
            "End of epoch 624 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000878\n",
            "(epoch: 625, iters: 16, time: 2.023, data: 0.002) G_GAN: 3.579 G_L1: 12.508 D_real: 0.119 D_fake: 0.053 \n",
            "saving the latest model (epoch 625, total_iters 10000)\n",
            "saving the model at the end of epoch 625, iters 10000\n",
            "End of epoch 625 / 800 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000873\n",
            "End of epoch 626 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000868\n",
            "End of epoch 627 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000863\n",
            "End of epoch 628 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000858\n",
            "End of epoch 629 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000853\n",
            "saving the model at the end of epoch 630, iters 10080\n",
            "End of epoch 630 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000848\n",
            "End of epoch 631 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000843\n",
            "(epoch: 632, iters: 4, time: 0.085, data: 0.259) G_GAN: 2.362 G_L1: 12.999 D_real: 0.429 D_fake: 0.048 \n",
            "End of epoch 632 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000838\n",
            "End of epoch 633 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000833\n",
            "End of epoch 634 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000828\n",
            "saving the model at the end of epoch 635, iters 10160\n",
            "End of epoch 635 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000823\n",
            "End of epoch 636 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000818\n",
            "End of epoch 637 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000813\n",
            "(epoch: 638, iters: 8, time: 0.087, data: 0.004) G_GAN: 3.229 G_L1: 13.605 D_real: 0.032 D_fake: 0.163 \n",
            "End of epoch 638 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000808\n",
            "End of epoch 639 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000803\n",
            "saving the model at the end of epoch 640, iters 10240\n",
            "End of epoch 640 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000798\n",
            "End of epoch 641 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000793\n",
            "End of epoch 642 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000788\n",
            "End of epoch 643 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000783\n",
            "(epoch: 644, iters: 12, time: 0.087, data: 0.001) G_GAN: 2.876 G_L1: 13.732 D_real: 0.123 D_fake: 0.089 \n",
            "End of epoch 644 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000778\n",
            "saving the model at the end of epoch 645, iters 10320\n",
            "End of epoch 645 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0000773\n",
            "End of epoch 646 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000768\n",
            "End of epoch 647 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000763\n",
            "End of epoch 648 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000758\n",
            "End of epoch 649 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000753\n",
            "(epoch: 650, iters: 16, time: 2.109, data: 0.001) G_GAN: 4.201 G_L1: 13.295 D_real: 0.023 D_fake: 0.036 \n",
            "saving the model at the end of epoch 650, iters 10400\n",
            "End of epoch 650 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000748\n",
            "End of epoch 651 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000743\n",
            "End of epoch 652 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000738\n",
            "End of epoch 653 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000733\n",
            "End of epoch 654 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000728\n",
            "saving the model at the end of epoch 655, iters 10480\n",
            "End of epoch 655 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000723\n",
            "End of epoch 656 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000718\n",
            "(epoch: 657, iters: 4, time: 0.078, data: 0.295) G_GAN: 3.140 G_L1: 13.491 D_real: 0.088 D_fake: 0.084 \n",
            "End of epoch 657 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000713\n",
            "End of epoch 658 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000708\n",
            "End of epoch 659 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000703\n",
            "saving the model at the end of epoch 660, iters 10560\n",
            "End of epoch 660 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000698\n",
            "End of epoch 661 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000693\n",
            "End of epoch 662 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000688\n",
            "(epoch: 663, iters: 8, time: 0.087, data: 0.003) G_GAN: 3.100 G_L1: 14.150 D_real: 0.055 D_fake: 0.139 \n",
            "End of epoch 663 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000683\n",
            "End of epoch 664 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000678\n",
            "saving the model at the end of epoch 665, iters 10640\n",
            "End of epoch 665 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000673\n",
            "End of epoch 666 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000668\n",
            "End of epoch 667 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000663\n",
            "End of epoch 668 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000658\n",
            "(epoch: 669, iters: 12, time: 0.087, data: 0.000) G_GAN: 3.371 G_L1: 13.274 D_real: 0.122 D_fake: 0.094 \n",
            "End of epoch 669 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000653\n",
            "saving the model at the end of epoch 670, iters 10720\n",
            "End of epoch 670 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000648\n",
            "End of epoch 671 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000643\n",
            "End of epoch 672 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000638\n",
            "End of epoch 673 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000633\n",
            "End of epoch 674 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000628\n",
            "(epoch: 675, iters: 16, time: 2.210, data: 0.002) G_GAN: 2.601 G_L1: 14.778 D_real: 0.323 D_fake: 0.039 \n",
            "saving the model at the end of epoch 675, iters 10800\n",
            "End of epoch 675 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000623\n",
            "End of epoch 676 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000618\n",
            "End of epoch 677 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000613\n",
            "End of epoch 678 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000608\n",
            "End of epoch 679 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000603\n",
            "saving the model at the end of epoch 680, iters 10880\n",
            "End of epoch 680 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0000599\n",
            "End of epoch 681 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 682, iters: 4, time: 0.082, data: 0.374) G_GAN: 3.496 G_L1: 14.070 D_real: 0.122 D_fake: 0.067 \n",
            "End of epoch 682 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000589\n",
            "End of epoch 683 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000584\n",
            "End of epoch 684 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000579\n",
            "saving the model at the end of epoch 685, iters 10960\n",
            "End of epoch 685 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000574\n",
            "End of epoch 686 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000569\n",
            "End of epoch 687 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000564\n",
            "(epoch: 688, iters: 8, time: 0.086, data: 0.005) G_GAN: 3.184 G_L1: 14.721 D_real: 0.166 D_fake: 0.058 \n",
            "End of epoch 688 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000559\n",
            "End of epoch 689 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000554\n",
            "saving the model at the end of epoch 690, iters 11040\n",
            "End of epoch 690 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000549\n",
            "End of epoch 691 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000544\n",
            "End of epoch 692 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000539\n",
            "End of epoch 693 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000534\n",
            "(epoch: 694, iters: 12, time: 0.087, data: 0.001) G_GAN: 3.197 G_L1: 14.460 D_real: 0.072 D_fake: 0.095 \n",
            "End of epoch 694 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000529\n",
            "saving the model at the end of epoch 695, iters 11120\n",
            "End of epoch 695 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000524\n",
            "End of epoch 696 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000519\n",
            "End of epoch 697 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000514\n",
            "End of epoch 698 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000509\n",
            "End of epoch 699 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000504\n",
            "(epoch: 700, iters: 16, time: 2.263, data: 0.001) G_GAN: 2.621 G_L1: 13.303 D_real: 0.196 D_fake: 0.114 \n",
            "saving the model at the end of epoch 700, iters 11200\n",
            "End of epoch 700 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000499\n",
            "End of epoch 701 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000494\n",
            "End of epoch 702 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000489\n",
            "End of epoch 703 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000484\n",
            "End of epoch 704 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000479\n",
            "saving the model at the end of epoch 705, iters 11280\n",
            "End of epoch 705 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000474\n",
            "End of epoch 706 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000469\n",
            "(epoch: 707, iters: 4, time: 0.083, data: 0.373) G_GAN: 3.417 G_L1: 13.484 D_real: 0.082 D_fake: 0.051 \n",
            "End of epoch 707 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000464\n",
            "End of epoch 708 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000459\n",
            "End of epoch 709 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000454\n",
            "saving the model at the end of epoch 710, iters 11360\n",
            "End of epoch 710 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000449\n",
            "End of epoch 711 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000444\n",
            "End of epoch 712 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000439\n",
            "(epoch: 713, iters: 8, time: 0.086, data: 0.004) G_GAN: 3.602 G_L1: 12.707 D_real: 0.042 D_fake: 0.078 \n",
            "End of epoch 713 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000434\n",
            "End of epoch 714 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000429\n",
            "saving the model at the end of epoch 715, iters 11440\n",
            "End of epoch 715 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000424\n",
            "End of epoch 716 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000419\n",
            "End of epoch 717 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000414\n",
            "End of epoch 718 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000409\n",
            "(epoch: 719, iters: 12, time: 0.086, data: 0.000) G_GAN: 2.771 G_L1: 13.782 D_real: 0.248 D_fake: 0.063 \n",
            "End of epoch 719 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000404\n",
            "saving the model at the end of epoch 720, iters 11520\n",
            "End of epoch 720 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000399\n",
            "End of epoch 721 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000394\n",
            "End of epoch 722 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000389\n",
            "End of epoch 723 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000384\n",
            "End of epoch 724 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000379\n",
            "(epoch: 725, iters: 16, time: 2.344, data: 0.001) G_GAN: 2.461 G_L1: 13.602 D_real: 0.178 D_fake: 0.174 \n",
            "saving the model at the end of epoch 725, iters 11600\n",
            "End of epoch 725 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000374\n",
            "End of epoch 726 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000369\n",
            "End of epoch 727 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000364\n",
            "End of epoch 728 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000359\n",
            "End of epoch 729 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000354\n",
            "saving the model at the end of epoch 730, iters 11680\n",
            "End of epoch 730 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000349\n",
            "End of epoch 731 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000344\n",
            "(epoch: 732, iters: 4, time: 0.083, data: 0.336) G_GAN: 2.785 G_L1: 13.405 D_real: 0.119 D_fake: 0.124 \n",
            "End of epoch 732 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000339\n",
            "End of epoch 733 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000334\n",
            "End of epoch 734 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000329\n",
            "saving the model at the end of epoch 735, iters 11760\n",
            "End of epoch 735 / 800 \t Time Taken: 4 sec\n",
            "learning rate = 0.0000324\n",
            "End of epoch 736 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000319\n",
            "End of epoch 737 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000314\n",
            "(epoch: 738, iters: 8, time: 0.088, data: 0.003) G_GAN: 3.927 G_L1: 13.317 D_real: 0.022 D_fake: 0.045 \n",
            "End of epoch 738 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000309\n",
            "End of epoch 739 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000304\n",
            "saving the model at the end of epoch 740, iters 11840\n",
            "End of epoch 740 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000299\n",
            "End of epoch 741 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000294\n",
            "End of epoch 742 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000289\n",
            "End of epoch 743 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000284\n",
            "(epoch: 744, iters: 12, time: 0.087, data: 0.003) G_GAN: 4.169 G_L1: 13.948 D_real: 0.097 D_fake: 0.027 \n",
            "End of epoch 744 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000279\n",
            "saving the model at the end of epoch 745, iters 11920\n",
            "End of epoch 745 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000274\n",
            "End of epoch 746 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000269\n",
            "End of epoch 747 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000264\n",
            "End of epoch 748 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000259\n",
            "End of epoch 749 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000254\n",
            "(epoch: 750, iters: 16, time: 2.484, data: 0.001) G_GAN: 2.948 G_L1: 13.854 D_real: 0.069 D_fake: 0.094 \n",
            "saving the model at the end of epoch 750, iters 12000\n",
            "End of epoch 750 / 800 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000249\n",
            "End of epoch 751 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000244\n",
            "End of epoch 752 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000239\n",
            "End of epoch 753 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000234\n",
            "End of epoch 754 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000229\n",
            "saving the model at the end of epoch 755, iters 12080\n",
            "End of epoch 755 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000224\n",
            "End of epoch 756 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000219\n",
            "(epoch: 757, iters: 4, time: 0.087, data: 0.337) G_GAN: 2.975 G_L1: 12.455 D_real: 0.123 D_fake: 0.086 \n",
            "End of epoch 757 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000214\n",
            "End of epoch 758 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000209\n",
            "End of epoch 759 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000204\n",
            "saving the model at the end of epoch 760, iters 12160\n",
            "End of epoch 760 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000200\n",
            "End of epoch 761 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000195\n",
            "End of epoch 762 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000190\n",
            "(epoch: 763, iters: 8, time: 0.088, data: 0.002) G_GAN: 2.977 G_L1: 13.930 D_real: 0.073 D_fake: 0.098 \n",
            "End of epoch 763 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000185\n",
            "End of epoch 764 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000180\n",
            "saving the model at the end of epoch 765, iters 12240\n",
            "End of epoch 765 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000175\n",
            "End of epoch 766 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000170\n",
            "End of epoch 767 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000165\n",
            "End of epoch 768 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000160\n",
            "(epoch: 769, iters: 12, time: 0.087, data: 0.002) G_GAN: 2.393 G_L1: 12.839 D_real: 0.124 D_fake: 0.158 \n",
            "End of epoch 769 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000155\n",
            "saving the model at the end of epoch 770, iters 12320\n",
            "End of epoch 770 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000150\n",
            "End of epoch 771 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000145\n",
            "End of epoch 772 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000140\n",
            "End of epoch 773 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000135\n",
            "End of epoch 774 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000130\n",
            "(epoch: 775, iters: 16, time: 2.478, data: 0.002) G_GAN: 3.326 G_L1: 11.328 D_real: 0.064 D_fake: 0.056 \n",
            "saving the model at the end of epoch 775, iters 12400\n",
            "End of epoch 775 / 800 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000125\n",
            "End of epoch 776 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000120\n",
            "End of epoch 777 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000115\n",
            "End of epoch 778 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000110\n",
            "End of epoch 779 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000105\n",
            "saving the model at the end of epoch 780, iters 12480\n",
            "End of epoch 780 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000100\n",
            "End of epoch 781 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000095\n",
            "(epoch: 782, iters: 4, time: 0.083, data: 0.392) G_GAN: 3.796 G_L1: 13.806 D_real: 0.088 D_fake: 0.041 \n",
            "End of epoch 782 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000090\n",
            "End of epoch 783 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000085\n",
            "End of epoch 784 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000080\n",
            "saving the model at the end of epoch 785, iters 12560\n",
            "End of epoch 785 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000075\n",
            "End of epoch 786 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000070\n",
            "End of epoch 787 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000065\n",
            "(epoch: 788, iters: 8, time: 0.088, data: 0.001) G_GAN: 3.260 G_L1: 12.704 D_real: 0.020 D_fake: 0.071 \n",
            "End of epoch 788 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000060\n",
            "End of epoch 789 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000055\n",
            "saving the model at the end of epoch 790, iters 12640\n",
            "End of epoch 790 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000050\n",
            "End of epoch 791 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000045\n",
            "End of epoch 792 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 793 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000035\n",
            "(epoch: 794, iters: 12, time: 0.087, data: 0.002) G_GAN: 3.176 G_L1: 12.132 D_real: 0.090 D_fake: 0.067 \n",
            "End of epoch 794 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000030\n",
            "saving the model at the end of epoch 795, iters 12720\n",
            "End of epoch 795 / 800 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000025\n",
            "End of epoch 796 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 797 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000015\n",
            "End of epoch 798 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000010\n",
            "End of epoch 799 / 800 \t Time Taken: 1 sec\n",
            "learning rate = 0.0000005\n",
            "(epoch: 800, iters: 16, time: 2.571, data: 0.002) G_GAN: 3.762 G_L1: 11.968 D_real: 0.022 D_fake: 0.041 \n",
            "saving the model at the end of epoch 800, iters 12800\n",
            "End of epoch 800 / 800 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL2G2vxBUOn1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-BDeLCnA7LE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "10dfc1f7-2210-4869-c2da-0ba0fbd15041"
      },
      "source": [
        "!python test.py --dataroot ./datasets/MyData --direction BtoA --model pix2pix --name day2night_MyData --netG unet_256 --dataset_mode aligned --norm batch "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/MyData             \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: BtoA                          \t[default: AtoB]\n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: test]\n",
            "               n_layers_D: 3                             \n",
            "                     name: day2night_MyData              \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_256                      \n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                     norm: batch                         \n",
            "                    ntest: inf                           \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: ./results/                    \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "loading the model from ./checkpoints/day2night_MyData/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "-----------------------------------------------\n",
            "processing (0000)-th image... ['./datasets/MyData/test/1.PNG']\n",
            "processing (0005)-th image... ['./datasets/MyData/test/14.PNG']\n",
            "processing (0010)-th image... ['./datasets/MyData/test/4.PNG']\n",
            "processing (0015)-th image... ['./datasets/MyData/test/9.PNG']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}